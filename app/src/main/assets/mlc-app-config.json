{
  "model_list": [
    {
      "model_id": "Phi-3.5-mini-instruct-q4f16_0-MLC",
      "model_lib": "phi3_q4f16_0_1ad1c79c0de46ffcc825e8181cc805e2",
      "model_url": "https://huggingface.co/mlc-ai/Phi-3.5-mini-instruct-q4f16_0-MLC",
      "estimated_vram_bytes": 4250586449
    },
    {
      "model_id": "Qwen3-0.6B-q0f16-MLC",
      "model_lib": "qwen3_q0f16_e709b04052d95e24b38d40e4259e1f14",
      "model_url": "https://huggingface.co/mlc-ai/Qwen3-0.6B-q0f16-MLC",
      "estimated_vram_bytes": 3000000000
    },
    {
      "model_id": "Qwen3-1.7B-q4f16_1-MLC",
      "model_lib": "qwen3_q4f16_1_1431bce2f7643ad37bb21ddc71153223",
      "model_url": "https://huggingface.co/mlc-ai/Qwen3-1.7B-q4f16_1-MLC",
      "estimated_vram_bytes": 3000000000
    },
    {
      "model_id": "gemma-2-2b-it-q4f16_1-MLC",
      "model_lib": "gemma2_q4f16_1_5cc7dbd3ae3d1040984d9720b2d7b7d4",
      "model_url": "https://huggingface.co/mlc-ai/gemma-2-2b-it-q4f16_1-MLC",
      "estimated_vram_bytes": 3000000000
    },
    {
      "model_id": "Llama-3.2-3B-Instruct-q4f16_0-MLC",
      "model_lib": "llama_q4f16_0_4f9f463aaf4b0ede5dc8c431d8a8fb3b",
      "model_url": "https://huggingface.co/mlc-ai/Llama-3.2-3B-Instruct-q4f16_0-MLC",
      "estimated_vram_bytes": 4679979417
    },
    {
      "model_id": "Mistral-7B-Instruct-v0.3-q4f16_1-MLC",
      "model_lib": "mistral_q4f16_1_c2cba77a6def4dd52f7e20b5d8576ab5",
      "model_url": "https://huggingface.co/mlc-ai/Mistral-7B-Instruct-v0.3-q4f16_1-MLC",
      "estimated_vram_bytes": 4115131883
    }
  ]
}
